{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2. Finding and Wrangling Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to Find Time Series Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepared Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Machine Learning Repository : https://archive.ics.uci.edu/ml/index.php\n",
    "\n",
    "The UEA and UCR Time Series Classification Repository: http://www.timeseriesclassification.com/\n",
    "\n",
    "Government time series data sets: \n",
    "\n",
    "https://www.ncdc.noaa.gov/cdo-web/datasets\n",
    "\n",
    "https://www.bls.gov/\n",
    "\n",
    "https://fred.stlouisfed.org/\n",
    "\n",
    "https://www.cdc.gov/flu/weekly/fluviewinteractive.htm\n",
    "\n",
    "Additional:\n",
    "\n",
    "https://www.comp-engine.org/\n",
    "\n",
    "https://cran.r-project.org/web/packages/Mcomp/index.html\n",
    "\n",
    "https://github.com/carlanetto/M4comp2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Worked Example: Assembling a Time Series Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_csv('BookRepo-master/Ch02/data/emails.csv')\n",
    "YearJoined = pd.read_csv('BookRepo-master/Ch02/data/year_joined.csv')\n",
    "donations =  pd.read_csv('BookRepo-master/Ch02/data/donations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>userStats</th>\n",
       "      <th>yearJoined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>silver</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user userStats  yearJoined\n",
       "0     0    silver        2014"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YearJoined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearJoined</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userStats</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           yearJoined\n",
       "userStats            \n",
       "1                1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## python\n",
    "YearJoined.groupby('user').count().groupby('userStats').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emailsOpened</th>\n",
       "      <th>user</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-06-29 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emailsOpened  user                 week\n",
       "0           3.0   1.0  2015-06-29 00:00:00"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emailsOpened</th>\n",
       "      <th>user</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [emailsOpened, user, week]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## python\n",
    "emails[emails.emailsOpened < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emailsOpened</th>\n",
       "      <th>user</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25464</th>\n",
       "      <td>1.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2017-12-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25465</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2017-12-11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25466</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2017-12-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25467</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25468</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-01-08 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25469</th>\n",
       "      <td>2.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-01-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25470</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-01-22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25471</th>\n",
       "      <td>2.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-01-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25472</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-02-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25473</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-02-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25474</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-02-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25475</th>\n",
       "      <td>2.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25476</th>\n",
       "      <td>2.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-03-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25477</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-03-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25478</th>\n",
       "      <td>2.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-03-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25479</th>\n",
       "      <td>2.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-03-26 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25480</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-04-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25481</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-04-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-04-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25483</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-04-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25484</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-05-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25485</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-05-14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25486</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-05-21 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25487</th>\n",
       "      <td>3.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>2018-05-28 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       emailsOpened   user                 week\n",
       "25464           1.0  998.0  2017-12-04 00:00:00\n",
       "25465           3.0  998.0  2017-12-11 00:00:00\n",
       "25466           3.0  998.0  2017-12-18 00:00:00\n",
       "25467           3.0  998.0  2018-01-01 00:00:00\n",
       "25468           3.0  998.0  2018-01-08 00:00:00\n",
       "25469           2.0  998.0  2018-01-15 00:00:00\n",
       "25470           3.0  998.0  2018-01-22 00:00:00\n",
       "25471           2.0  998.0  2018-01-29 00:00:00\n",
       "25472           3.0  998.0  2018-02-05 00:00:00\n",
       "25473           3.0  998.0  2018-02-12 00:00:00\n",
       "25474           3.0  998.0  2018-02-19 00:00:00\n",
       "25475           2.0  998.0  2018-02-26 00:00:00\n",
       "25476           2.0  998.0  2018-03-05 00:00:00\n",
       "25477           3.0  998.0  2018-03-12 00:00:00\n",
       "25478           2.0  998.0  2018-03-19 00:00:00\n",
       "25479           2.0  998.0  2018-03-26 00:00:00\n",
       "25480           3.0  998.0  2018-04-02 00:00:00\n",
       "25481           3.0  998.0  2018-04-09 00:00:00\n",
       "25482           3.0  998.0  2018-04-16 00:00:00\n",
       "25483           3.0  998.0  2018-04-30 00:00:00\n",
       "25484           3.0  998.0  2018-05-07 00:00:00\n",
       "25485           3.0  998.0  2018-05-14 00:00:00\n",
       "25486           3.0  998.0  2018-05-21 00:00:00\n",
       "25487           3.0  998.0  2018-05-28 00:00:00"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[emails.user == 998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-05-28 00:00:00'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(max(emails[emails.user == 998].week))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-12-04 00:00:00'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(emails[emails.user == 998].week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(max(emails[emails.member == 998].week) -\n",
    "min(emails[emails.member == 998].week)).days/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[emails.user == 998].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_idx = pd.MultiIndex.from_product((set(emails.week),\n",
    "set(emails.user)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_email = emails.set_index(['week', 'member']).\n",
    "reindex(complete_idx, fill_value = 0).\n",
    "reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_email.columns = ['week', 'member', 'EmailsOpened']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## python\n",
    "cutoff_dates = emails.groupby('member').week.\n",
    "agg(['min', 'max']).reset_index)\n",
    "cutoff_dates = cutoff_dates.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## python\n",
    ">>> for _, row in cutoff_dates.iterrows():\n",
    ">>> member = row['member']\n",
    ">>> start_date = row['min']\n",
    ">>> end_date = row['max']\n",
    ">>> all_email.drop(\n",
    "all_email[all_email.member == member]\n",
    "[all_email.week < start_date].index, inplace=True)\n",
    ">>> all_email.drop(all_email[all_email.member == member]\n",
    "[all_email.week > end_date].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## python\n",
    ">>> donations.timestamp = pd.to_datetime(donations.timestamp)\n",
    ">>> donations.set_index('timestamp', inplace = True)\n",
    ">>> agg_don = donations.groupby('member').apply(\n",
    "lambda df: df.amount.resample(\"W-MON\").sum().dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## python\n",
    ">>> for member, member_email in all_email.groupby('member'):\n",
    ">>> member_donations = agg_donations[agg_donations.member\n",
    "== member]\n",
    ">>> member_donations.set_index('timestamp', inplace = True)\n",
    ">>> member_email.set_index ('week', inplace = True)\n",
    "\n",
    ">>> member_email = all_email[all_email.member == member]\n",
    ">>> member_email.sort_values('week').set_index('week')\n",
    ">>> df = pd.merge(member_email, member_donations, how = 'left',\n",
    "left_index = True,\n",
    "right_index = True)\n",
    ">>> df.fillna(0)\n",
    ">>> df['member'] = df.member_x\n",
    ">>> merged_df = merged_df.append(df.reset_index()\n",
    "[['member', 'week', 'emailsOpened',\n",
    "'amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## python\n",
    ">>> df = merged_df[merged_df.member == 998]\n",
    ">>> df['target'] = df.amount.shift(1)\n",
    ">>> df = df.fillna(0)\n",
    ">>> df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## python\n",
    ">>> df['dt'] = df.time - df.time.shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-761fdbb6bded>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-761fdbb6bded>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Missing data\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Missing data\n",
    "Changing the frequency of a time series (that is, upsampling and\n",
    "downsampling)\n",
    "Smoothing data\n",
    "Addressing seasonality in data\n",
    "Preventing unintentional lookaheads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a few specific ways to fill in numbers for those missing values:\n",
    "\n",
    "Forward fill\n",
    "\n",
    "Moving average\n",
    "\n",
    "Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOKAHEAD\n",
    "\n",
    "The term lookahead is used in time series analysis to denote any\n",
    "\n",
    "knowledge of the future. You shouldn’t have such knowledge when\n",
    "\n",
    "designing, training, or evaluating a model. A lookahead is a way, through\n",
    "\n",
    "data, to find out something about the future earlier than you ought to\n",
    "\n",
    "know it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling:\n",
    "\n",
    "downsampling is as simple as selecting\n",
    "\n",
    "out every nth element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling:\n",
    "\n",
    "Irregular time series\n",
    "\n",
    "Inputs sampled at different frequencies\n",
    "\n",
    "Knowledge of time series dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing Data\n",
    "\n",
    "Exponential smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = ['Date','Passengers']\n",
    "air = pd.read_csv('BookRepo-master\\Ch02\\data\\AirPassengers.csv', header=None)\n",
    "air.columns = Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date  Passengers\n",
       "0  1949-01         112\n",
       "1  1949-02         118\n",
       "2  1949-03         132\n",
       "3  1949-04         129\n",
       "4  1949-05         121"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'ewma'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-346b0479064e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Smooth.5'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mewma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mair\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPassengers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Smooth.9'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mewma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mair\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPassengers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'ewma'"
     ]
    }
   ],
   "source": [
    "air['Smooth.5'] = pd.ewma(air, alpha = .5).Passengers\n",
    "air['Smooth.9'] = pd.ewma(air, alpha = .9).Passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "air['Smooth.5'] = air.ewm(alpha = .5).mean().Passengers\n",
    "air['Smooth.9'] = air.ewm(alpha = .9).mean().Passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>Smooth.5</th>\n",
       "      <th>Smooth.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01</td>\n",
       "      <td>112</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02</td>\n",
       "      <td>118</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>117.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03</td>\n",
       "      <td>132</td>\n",
       "      <td>125.142857</td>\n",
       "      <td>130.558559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>129</td>\n",
       "      <td>127.200000</td>\n",
       "      <td>129.155716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05</td>\n",
       "      <td>121</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>121.815498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1949-06</td>\n",
       "      <td>135</td>\n",
       "      <td>129.587302</td>\n",
       "      <td>133.681562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1949-07</td>\n",
       "      <td>148</td>\n",
       "      <td>138.866142</td>\n",
       "      <td>146.568157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1949-08</td>\n",
       "      <td>148</td>\n",
       "      <td>143.450980</td>\n",
       "      <td>147.856816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1949-09</td>\n",
       "      <td>136</td>\n",
       "      <td>139.718200</td>\n",
       "      <td>137.185682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1949-10</td>\n",
       "      <td>119</td>\n",
       "      <td>129.348974</td>\n",
       "      <td>120.818568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1949-11</td>\n",
       "      <td>104</td>\n",
       "      <td>116.668295</td>\n",
       "      <td>105.681857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date  Passengers    Smooth.5    Smooth.9\n",
       "0   1949-01         112  112.000000  112.000000\n",
       "1   1949-02         118  116.000000  117.454545\n",
       "2   1949-03         132  125.142857  130.558559\n",
       "3   1949-04         129  127.200000  129.155716\n",
       "4   1949-05         121  124.000000  121.815498\n",
       "5   1949-06         135  129.587302  133.681562\n",
       "6   1949-07         148  138.866142  146.568157\n",
       "7   1949-08         148  143.450980  147.856816\n",
       "8   1949-09         136  139.718200  137.185682\n",
       "9   1949-10         119  129.348974  120.818568\n",
       "10  1949-11         104  116.668295  105.681857"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kalman and LOESS incorporate data both earlier and later in\n",
    "\n",
    "time, so if you use these methods keep in mind the leak of information\n",
    "\n",
    "backward in time, as well as the fact that they are usually not appropriate for\n",
    "\n",
    "preparing data to be used in forecasting applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonal Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 11, 27, 14, 41, 59, 738794)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 11, 27, 11, 42, 11, 368460)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 11, 27, 14, 42, 21, 714051, tzinfo=datetime.timezone.utc)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now(datetime.timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'US/Pacific'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "western = pytz.timezone('US/Pacific')\n",
    "western.zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_dt = western.localize(datetime.datetime(2018, 5, 15, 12, 34, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 5, 15, 12, 34, tzinfo=<DstTzInfo 'US/Pacific' PDT-1 day, 17:00:00 DST>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Africa/Abidjan', 'Africa/Accra', 'Africa/Addis_Ababa', 'Africa/Algiers', 'Africa/Asmara', 'Africa/Bamako', 'Africa/Bangui', 'Africa/Banjul', 'Africa/Bissau', 'Africa/Blantyre', 'Africa/Brazzaville', 'Africa/Bujumbura', 'Africa/Cairo', 'Africa/Casablanca', 'Africa/Ceuta', 'Africa/Conakry', 'Africa/Dakar', 'Africa/Dar_es_Salaam', 'Africa/Djibouti', 'Africa/Douala', 'Africa/El_Aaiun', 'Africa/Freetown', 'Africa/Gaborone', 'Africa/Harare', 'Africa/Johannesburg', 'Africa/Juba', 'Africa/Kampala', 'Africa/Khartoum', 'Africa/Kigali', 'Africa/Kinshasa', 'Africa/Lagos', 'Africa/Libreville', 'Africa/Lome', 'Africa/Luanda', 'Africa/Lubumbashi', 'Africa/Lusaka', 'Africa/Malabo', 'Africa/Maputo', 'Africa/Maseru', 'Africa/Mbabane', 'Africa/Mogadishu', 'Africa/Monrovia', 'Africa/Nairobi', 'Africa/Ndjamena', 'Africa/Niamey', 'Africa/Nouakchott', 'Africa/Ouagadougou', 'Africa/Porto-Novo', 'Africa/Sao_Tome', 'Africa/Tripoli', 'Africa/Tunis', 'Africa/Windhoek', 'America/Adak', 'America/Anchorage', 'America/Anguilla', 'America/Antigua', 'America/Araguaina', 'America/Argentina/Buenos_Aires', 'America/Argentina/Catamarca', 'America/Argentina/Cordoba', 'America/Argentina/Jujuy', 'America/Argentina/La_Rioja', 'America/Argentina/Mendoza', 'America/Argentina/Rio_Gallegos', 'America/Argentina/Salta', 'America/Argentina/San_Juan', 'America/Argentina/San_Luis', 'America/Argentina/Tucuman', 'America/Argentina/Ushuaia', 'America/Aruba', 'America/Asuncion', 'America/Atikokan', 'America/Bahia', 'America/Bahia_Banderas', 'America/Barbados', 'America/Belem', 'America/Belize', 'America/Blanc-Sablon', 'America/Boa_Vista', 'America/Bogota', 'America/Boise', 'America/Cambridge_Bay', 'America/Campo_Grande', 'America/Cancun', 'America/Caracas', 'America/Cayenne', 'America/Cayman', 'America/Chicago', 'America/Chihuahua', 'America/Costa_Rica', 'America/Creston', 'America/Cuiaba', 'America/Curacao', 'America/Danmarkshavn', 'America/Dawson', 'America/Dawson_Creek', 'America/Denver', 'America/Detroit', 'America/Dominica', 'America/Edmonton', 'America/Eirunepe', 'America/El_Salvador', 'America/Fort_Nelson', 'America/Fortaleza', 'America/Glace_Bay', 'America/Godthab', 'America/Goose_Bay', 'America/Grand_Turk', 'America/Grenada', 'America/Guadeloupe', 'America/Guatemala', 'America/Guayaquil', 'America/Guyana', 'America/Halifax', 'America/Havana', 'America/Hermosillo', 'America/Indiana/Indianapolis', 'America/Indiana/Knox', 'America/Indiana/Marengo', 'America/Indiana/Petersburg', 'America/Indiana/Tell_City', 'America/Indiana/Vevay', 'America/Indiana/Vincennes', 'America/Indiana/Winamac', 'America/Inuvik', 'America/Iqaluit', 'America/Jamaica', 'America/Juneau', 'America/Kentucky/Louisville', 'America/Kentucky/Monticello', 'America/Kralendijk', 'America/La_Paz', 'America/Lima', 'America/Los_Angeles', 'America/Lower_Princes', 'America/Maceio', 'America/Managua', 'America/Manaus', 'America/Marigot', 'America/Martinique', 'America/Matamoros', 'America/Mazatlan', 'America/Menominee', 'America/Merida', 'America/Metlakatla', 'America/Mexico_City', 'America/Miquelon', 'America/Moncton', 'America/Monterrey', 'America/Montevideo', 'America/Montserrat', 'America/Nassau', 'America/New_York', 'America/Nipigon', 'America/Nome', 'America/Noronha', 'America/North_Dakota/Beulah', 'America/North_Dakota/Center', 'America/North_Dakota/New_Salem', 'America/Ojinaga', 'America/Panama', 'America/Pangnirtung', 'America/Paramaribo', 'America/Phoenix', 'America/Port-au-Prince', 'America/Port_of_Spain', 'America/Porto_Velho', 'America/Puerto_Rico', 'America/Punta_Arenas', 'America/Rainy_River', 'America/Rankin_Inlet', 'America/Recife', 'America/Regina', 'America/Resolute', 'America/Rio_Branco', 'America/Santarem', 'America/Santiago', 'America/Santo_Domingo', 'America/Sao_Paulo', 'America/Scoresbysund', 'America/Sitka', 'America/St_Barthelemy', 'America/St_Johns', 'America/St_Kitts', 'America/St_Lucia', 'America/St_Thomas', 'America/St_Vincent', 'America/Swift_Current', 'America/Tegucigalpa', 'America/Thule', 'America/Thunder_Bay', 'America/Tijuana', 'America/Toronto', 'America/Tortola', 'America/Vancouver', 'America/Whitehorse', 'America/Winnipeg', 'America/Yakutat', 'America/Yellowknife', 'Antarctica/Casey', 'Antarctica/Davis', 'Antarctica/DumontDUrville', 'Antarctica/Macquarie', 'Antarctica/Mawson', 'Antarctica/McMurdo', 'Antarctica/Palmer', 'Antarctica/Rothera', 'Antarctica/Syowa', 'Antarctica/Troll', 'Antarctica/Vostok', 'Arctic/Longyearbyen', 'Asia/Aden', 'Asia/Almaty', 'Asia/Amman', 'Asia/Anadyr', 'Asia/Aqtau', 'Asia/Aqtobe', 'Asia/Ashgabat', 'Asia/Atyrau', 'Asia/Baghdad', 'Asia/Bahrain', 'Asia/Baku', 'Asia/Bangkok', 'Asia/Barnaul', 'Asia/Beirut', 'Asia/Bishkek', 'Asia/Brunei', 'Asia/Chita', 'Asia/Choibalsan', 'Asia/Colombo', 'Asia/Damascus', 'Asia/Dhaka', 'Asia/Dili', 'Asia/Dubai', 'Asia/Dushanbe', 'Asia/Famagusta', 'Asia/Gaza', 'Asia/Hebron', 'Asia/Ho_Chi_Minh', 'Asia/Hong_Kong', 'Asia/Hovd', 'Asia/Irkutsk', 'Asia/Jakarta', 'Asia/Jayapura', 'Asia/Jerusalem', 'Asia/Kabul', 'Asia/Kamchatka', 'Asia/Karachi', 'Asia/Kathmandu', 'Asia/Khandyga', 'Asia/Kolkata', 'Asia/Krasnoyarsk', 'Asia/Kuala_Lumpur', 'Asia/Kuching', 'Asia/Kuwait', 'Asia/Macau', 'Asia/Magadan', 'Asia/Makassar', 'Asia/Manila', 'Asia/Muscat', 'Asia/Nicosia', 'Asia/Novokuznetsk', 'Asia/Novosibirsk', 'Asia/Omsk', 'Asia/Oral', 'Asia/Phnom_Penh', 'Asia/Pontianak', 'Asia/Pyongyang', 'Asia/Qatar', 'Asia/Qostanay', 'Asia/Qyzylorda', 'Asia/Riyadh', 'Asia/Sakhalin', 'Asia/Samarkand', 'Asia/Seoul', 'Asia/Shanghai', 'Asia/Singapore', 'Asia/Srednekolymsk', 'Asia/Taipei', 'Asia/Tashkent', 'Asia/Tbilisi', 'Asia/Tehran', 'Asia/Thimphu', 'Asia/Tokyo', 'Asia/Tomsk', 'Asia/Ulaanbaatar', 'Asia/Urumqi', 'Asia/Ust-Nera', 'Asia/Vientiane', 'Asia/Vladivostok', 'Asia/Yakutsk', 'Asia/Yangon', 'Asia/Yekaterinburg', 'Asia/Yerevan', 'Atlantic/Azores', 'Atlantic/Bermuda', 'Atlantic/Canary', 'Atlantic/Cape_Verde', 'Atlantic/Faroe', 'Atlantic/Madeira', 'Atlantic/Reykjavik', 'Atlantic/South_Georgia', 'Atlantic/St_Helena', 'Atlantic/Stanley', 'Australia/Adelaide', 'Australia/Brisbane', 'Australia/Broken_Hill', 'Australia/Currie', 'Australia/Darwin', 'Australia/Eucla', 'Australia/Hobart', 'Australia/Lindeman', 'Australia/Lord_Howe', 'Australia/Melbourne', 'Australia/Perth', 'Australia/Sydney', 'Canada/Atlantic', 'Canada/Central', 'Canada/Eastern', 'Canada/Mountain', 'Canada/Newfoundland', 'Canada/Pacific', 'Europe/Amsterdam', 'Europe/Andorra', 'Europe/Astrakhan', 'Europe/Athens', 'Europe/Belgrade', 'Europe/Berlin', 'Europe/Bratislava', 'Europe/Brussels', 'Europe/Bucharest', 'Europe/Budapest', 'Europe/Busingen', 'Europe/Chisinau', 'Europe/Copenhagen', 'Europe/Dublin', 'Europe/Gibraltar', 'Europe/Guernsey', 'Europe/Helsinki', 'Europe/Isle_of_Man', 'Europe/Istanbul', 'Europe/Jersey', 'Europe/Kaliningrad', 'Europe/Kiev', 'Europe/Kirov', 'Europe/Lisbon', 'Europe/Ljubljana', 'Europe/London', 'Europe/Luxembourg', 'Europe/Madrid', 'Europe/Malta', 'Europe/Mariehamn', 'Europe/Minsk', 'Europe/Monaco', 'Europe/Moscow', 'Europe/Oslo', 'Europe/Paris', 'Europe/Podgorica', 'Europe/Prague', 'Europe/Riga', 'Europe/Rome', 'Europe/Samara', 'Europe/San_Marino', 'Europe/Sarajevo', 'Europe/Saratov', 'Europe/Simferopol', 'Europe/Skopje', 'Europe/Sofia', 'Europe/Stockholm', 'Europe/Tallinn', 'Europe/Tirane', 'Europe/Ulyanovsk', 'Europe/Uzhgorod', 'Europe/Vaduz', 'Europe/Vatican', 'Europe/Vienna', 'Europe/Vilnius', 'Europe/Volgograd', 'Europe/Warsaw', 'Europe/Zagreb', 'Europe/Zaporozhye', 'Europe/Zurich', 'GMT', 'Indian/Antananarivo', 'Indian/Chagos', 'Indian/Christmas', 'Indian/Cocos', 'Indian/Comoro', 'Indian/Kerguelen', 'Indian/Mahe', 'Indian/Maldives', 'Indian/Mauritius', 'Indian/Mayotte', 'Indian/Reunion', 'Pacific/Apia', 'Pacific/Auckland', 'Pacific/Bougainville', 'Pacific/Chatham', 'Pacific/Chuuk', 'Pacific/Easter', 'Pacific/Efate', 'Pacific/Enderbury', 'Pacific/Fakaofo', 'Pacific/Fiji', 'Pacific/Funafuti', 'Pacific/Galapagos', 'Pacific/Gambier', 'Pacific/Guadalcanal', 'Pacific/Guam', 'Pacific/Honolulu', 'Pacific/Kiritimati', 'Pacific/Kosrae', 'Pacific/Kwajalein', 'Pacific/Majuro', 'Pacific/Marquesas', 'Pacific/Midway', 'Pacific/Nauru', 'Pacific/Niue', 'Pacific/Norfolk', 'Pacific/Noumea', 'Pacific/Pago_Pago', 'Pacific/Palau', 'Pacific/Pitcairn', 'Pacific/Pohnpei', 'Pacific/Port_Moresby', 'Pacific/Rarotonga', 'Pacific/Saipan', 'Pacific/Tahiti', 'Pacific/Tarawa', 'Pacific/Tongatapu', 'Pacific/Wake', 'Pacific/Wallis', 'US/Alaska', 'US/Arizona', 'US/Central', 'US/Eastern', 'US/Hawaii', 'US/Mountain', 'US/Pacific', 'UTC']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytz.common_timezones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Europe/Istanbul']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytz.country_timezones('tr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preventing Lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIntentionally introduce a lookahead and see how your model\\nbehaves. Try various degrees of lookahead, so you have an idea how\\nit shifts accuracy. If you have some idea of the accuracy with\\nlookahead, you have an idea of what the ceiling on a real model\\nwithout unfair knowledge of the future will do. Remember that many\\ntime series problems are extremely difficult, so a model with a\\nlookahead may seem great until you realize you are dealing with a\\nhigh-noise/low-signal data set.\\n\\nAdd features slowly, particularly features you might be processing,\\nso that you can look for jumps. One sign of a lookahead is when a\\nparticular feature is unexpectedly good, and there isn’t a very good\\nexplanation. At the top of your explanation list should always be\\n“lookahead.”\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Intentionally introduce a lookahead and see how your model\n",
    "behaves. Try various degrees of lookahead, so you have an idea how\n",
    "it shifts accuracy. If you have some idea of the accuracy with\n",
    "lookahead, you have an idea of what the ceiling on a real model\n",
    "without unfair knowledge of the future will do. Remember that many\n",
    "time series problems are extremely difficult, so a model with a\n",
    "lookahead may seem great until you realize you are dealing with a\n",
    "high-noise/low-signal data set.\n",
    "\n",
    "Add features slowly, particularly features you might be processing,\n",
    "so that you can look for jumps. One sign of a lookahead is when a\n",
    "particular feature is unexpectedly good, and there isn’t a very good\n",
    "explanation. At the top of your explanation list should always be\n",
    "“lookahead.”\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3. Exploratory Data Analysis for Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Familiar Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou will want to address the\\nsame exploratory questions you would ask about any new data set, such as:\\n\\nAre any of the columns strongly correlated with one another?\\n\\nWhat is the overall mean of an interesting variable? What is its\\nvariance?\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "You will want to address the\n",
    "same exploratory questions you would ask about any new data set, such as:\n",
    "\n",
    "Are any of the columns strongly correlated with one another?\n",
    "\n",
    "What is the overall mean of an interesting variable? What is its\n",
    "variance?\n",
    "\n",
    "To answer these, you can use familiar techniques such as plotting, taking\n",
    "summary statistics, applying histograms, and using targeted scatter plots.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhat is the range of values you see, and do they vary by time period\\nor some other logical unit of analysis?\\n\\nDoes the data look consistent and uniformly measured, or does it\\nsuggest changes in either measurement or behavior over time?\\n\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "What is the range of values you see, and do they vary by time period\n",
    "or some other logical unit of analysis?\n",
    "\n",
    "Does the data look consistent and uniformly measured, or does it\n",
    "suggest changes in either measurement or behavior over time?\n",
    "\n",
    "To answer these, you can use familiar techniques such as plotting, taking\n",
    "summary statistics, applying histograms, and using targeted scatter plots.\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
